import OpenAI from 'openai';
import { Pinecone } from '@pinecone-database/pinecone';
import { encode } from 'gpt-3-encoder';
import * as userService from './services/user-service.js';
import * as listingService from './services/listing-service.js';

// Initialize clients
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});
const pinecone = new Pinecone({ apiKey: process.env.PINECONE_API_KEY });

// Function to get the appropriate Pinecone index based on client config
function getPineconeIndex(clientConfig) {
  // Use client-specific index if available, otherwise fall back to shared index
  const indexName = clientConfig?.pineconeIndex || 'rachatbot-1536';
  console.log(`Using Pinecone index: ${indexName} for client: ${clientConfig?.clientName || 'Unknown'}`);
  return pinecone.index(indexName);
}

const embeddingModel = "text-embedding-3-small"; // Standardize on the 1536-dimension model
const generativeModel = "gpt-3.5-turbo";
const MAX_TOTAL_TOKENS = 4096; // Max tokens for gpt-3.5-turbo
const MAX_RESPONSE_TOKENS = 1000;
const CONTEXT_TOKEN_BUDGET = MAX_TOTAL_TOKENS - MAX_RESPONSE_TOKENS; // Reserve tokens for the response

const delay = (ms) => new Promise(resolve => setTimeout(resolve, ms));

function extractListingIdFromQuery(query) {
  const match = query.toLowerCase().match(/ap-\d+/);
  return match ? match[0] : null;
}

function mergeFilters(queryFilters, onboardingFilters) {
  const merged = { ...onboardingFilters, ...queryFilters };
  // A simple example of resolving conflicts, queryFilters take precedence
  // You might want to implement more sophisticated logic here based on your needs
  for (const key in queryFilters) {
    if (onboardingFilters.hasOwnProperty(key)) {
      console.log(`Overriding onboarding filter '${key}' with value from query.`);
    }
  }
  return merged;
}

function extractQueryFilters(query, currentListingPrice = null) {
  const filters = {};
  const lowerCaseQuery = query.toLowerCase();

  // Handle direct query for typology, e.g., "T1" or "t2"
  const typologyMatch = lowerCaseQuery.match(/\b(t\d)\b/i);
  if (typologyMatch) {
    filters.type = typologyMatch[1].toUpperCase();
  }

  // Number of Bedrooms (exact, greater than, less than)
  let match = lowerCaseQuery.match(/(\d+)\s*quartos/);
  if (match) {
    const num = parseInt(match[1], 10);
    if (!isNaN(num)) {
      filters.num_bedrooms = num;
    }
  }

  match = lowerCaseQuery.match(/mais de\s*(\d+)\s*quartos/);
  if (match) {
    const num = parseInt(match[1], 10);
    if (!isNaN(num)) {
      filters.num_bedrooms = { "$gt": num };
    }
  }

  match = lowerCaseQuery.match(/menos de\s*(\d+)\s*quartos/);
  if (match) {
    const num = parseInt(match[1], 10);
    if (!isNaN(num)) {
      filters.num_bedrooms = { "$lt": num };
    }
  }

  // Number of Bathrooms
  match = lowerCaseQuery.match(/(\d+)\s*casas de banho/);
  if (match) {
    const num = parseInt(match[1], 10);
    if (!isNaN(num)) {
      filters.num_bathrooms = num;
    }
  }

  // Total Area (less than X m2)
  match = lowerCaseQuery.match(/menos de\s*([\d.,]+)\s*m¬≤/);
  if (match) {
    const area = parseFloat(match[1].replace(',', '.'));
    if (!isNaN(area)) {
      filters.total_area_sqm = { "$lt": area };
    }
  }

  // Price (less than X‚Ç¨)
  match = lowerCaseQuery.match(/menos de\s*([\d.,]+)‚Ç¨/);
  if (match) {
    const price = parseFloat(match[1].replace(/\./g, '').replace(',', '.'));
    if (!isNaN(price)) {
      filters.price_eur = { "$lt": price };
    }
  }

  if (currentListingPrice && (lowerCaseQuery.includes('pre√ßo') || lowerCaseQuery.includes('custo') || lowerCaseQuery.includes('valor'))) {
    // This case is handled by the LLM with context
  }

  if (currentListingPrice) {
    if (lowerCaseQuery.includes('mais baixo') || lowerCaseQuery.includes('mais barato')) {
      filters.price_eur = { "$lt": currentListingPrice };
    } else if (lowerCaseQuery.includes('mais alto') || lowerCaseQuery.includes('mais caro')) {
      filters.price_eur = { "$gt": currentListingPrice };
    }
  }

  // Boolean features
  if (lowerCaseQuery.includes('piscina')) filters.has_pool = true;
  if (lowerCaseQuery.includes('jardim')) filters.has_garden = true;
  if (lowerCaseQuery.includes('garagem')) filters.has_garage = true;
  if (lowerCaseQuery.includes('elevador')) filters.has_elevator = true;
  if (lowerCaseQuery.includes('varanda')) filters.has_balcony = true;
  if (lowerCaseQuery.includes('terra√ßo')) filters.has_terrace = true;
  if (lowerCaseQuery.includes('gin√°sio')) filters.has_gym = true;
  if (lowerCaseQuery.includes('carregamento el√©trico')) filters.has_electric_car_charging = true;
  if (lowerCaseQuery.includes('animais permitidos')) filters.pets_allowed = true;

  // Debug what filters were extracted
  if (Object.keys(filters).length > 0) {
    console.log(`üîç extractQueryFilters extracted: ${JSON.stringify(filters, null, 2)} from query: "${query}"`);
  } else {
    console.log(`üîç extractQueryFilters found no filters in query: "${query}"`);
  }
  
  return filters;
}

/**
 * Converts onboarding answers into a Pinecone metadata filter object.
 * @param {object} onboardingAnswers - The user's answers from the onboarding process.
 * @returns {object} A Pinecone filter object.
 */
function convertOnboardingToFilters(onboardingAnswers) {
  if (!onboardingAnswers) {
    return {};
  }

  const filters = {};
  const { tipologia, orcamento, localizacao, caracteristicas } = onboardingAnswers;

  // Type (T1, T2, etc.) - maps to 'type' metadata field
  if (tipologia) {
    filters.type = tipologia;
  }

  // Budget - maps to 'price_eur' metadata field
  if (orcamento) {
    const range = orcamento.match(/(\d+)k-(\d+)k/);
    if (range) {
      const min = parseInt(range[1], 10) * 1000;
      const max = parseInt(range[2], 10) * 1000;
      filters.price_eur = { "$gte": min, "$lte": max };
    } else if (orcamento.includes('<')) {
      const max = parseInt(orcamento.replace(/[<k]/g, ''), 10) * 1000;
      filters.price_eur = { "$lte": max };
    } else if (orcamento.includes('>')) {
      const min = parseInt(orcamento.replace(/[>k]/g, ''), 10) * 1000;
      filters.price_eur = { "$gte": min };
    }
  }

  // Location - maps to 'location' metadata field
  if (localizacao) {
    filters.location = localizacao.replace(/_/g, ' ');
  }

  // Characteristics (e.g., 'garagem') - maps to boolean 'has_garagem' metadata field
  if (caracteristicas && Array.isArray(caracteristicas)) {
    caracteristicas.forEach(feature => {
      if (feature) {
        filters[`has_${feature}`] = true;
      }
    });
  }
  
  console.log(`üîç Converted onboarding answers to filters: ${JSON.stringify(filters, null, 2)}`);
  return filters;
}

async function performHybridSearch(searchVector, clientConfig, externalContext = null, originalQuery = "", userContext = null, queryFilters = {}) {
  // Validate search vector before proceeding
  if (!searchVector) {
    console.error('Search vector is null or undefined');
    throw new Error('Invalid search vector: vector is required for Pinecone queries');
  }
  
  if (!Array.isArray(searchVector)) {
    console.error('Search vector is not an array:', typeof searchVector);
    throw new Error('Invalid search vector: must be an array of numbers');
  }
  
  if (searchVector.length === 0) {
    console.error('Search vector is empty');
    throw new Error('Invalid search vector: vector cannot be empty');
  }
  
  if (typeof searchVector[0] !== 'number' || isNaN(searchVector[0])) {
    console.error('Search vector contains invalid values:', searchVector.slice(0, 5));
    throw new Error('Invalid search vector: must contain numeric values');
  }
  
  console.log(`[${clientConfig.clientName}] Using search vector with ${searchVector.length} dimensions`);

  // Get the client-specific Pinecone index
  const clientPineconeIndex = getPineconeIndex(clientConfig);
  
  // For client-specific indexes, we don't need to filter by client_id since the entire index
  // is dedicated to this client, but we'll keep it for backward compatibility
  const baseFilter = {
    client_id: clientConfig.clientId,
  };

  if (userContext && userContext.role === 'promoter') {
    try {
      const assignedListings = await userService.getListingsByAgentId(userContext.userId);
      if (assignedListings.length > 0) {
        baseFilter.listing_id = { "$in": assignedListings };
      } else {
        return { matches: [] };
      }
    } catch (error) {
      console.error(`Error applying agent filtering for user ${userContext.userId}:`, error);
      return { matches: [] };
    }
  }

  const contextListingId = externalContext?.type === 'listing' ? externalContext.value : null;
  const contextDevelopmentId = externalContext?.type === 'development' ? externalContext.value : clientConfig.defaultDevelopmentId;
  
  const queries = [];

  // 1. Targeted Listing Query
  if (contextListingId) {
    console.log(`Queueing targeted query for listing_id: ${contextListingId}`);
    const listingQueryParams = {
      vector: searchVector,
      topK: 10,
      includeMetadata: true,
      filter: { ...baseFilter, listing_id: contextListingId },
    };
    console.log('Listing Query Params:', JSON.stringify(listingQueryParams, null, 2));
    queries.push(clientPineconeIndex
      .namespace(process.env.PINECONE_NAMESPACE)
      .query(listingQueryParams)
    );
  } else {
    queries.push(Promise.resolve({ matches: [] })); // Add empty promise to keep array order
  }

  // 2. Targeted Development Query
  if (contextDevelopmentId) {
    console.log(`Queueing targeted query for development_id: ${contextDevelopmentId}`);
    const developmentQueryParams = {
      vector: searchVector,
      topK: 10,
      includeMetadata: true,
      filter: { ...baseFilter, development_id: contextDevelopmentId },
    };
    console.log('Development Query Params:', JSON.stringify(developmentQueryParams, null, 2));
    queries.push(clientPineconeIndex
      .namespace(process.env.PINECONE_NAMESPACE)
      .query(developmentQueryParams)
    );
  } else {
    queries.push(Promise.resolve({ matches: [] })); // Add empty promise
  }

  // 3. Broad Query
  console.log("Queueing broad query with filters:", JSON.stringify(queryFilters, null, 2));
  const initialFilter = { ...baseFilter, ...queryFilters };
  const broadQueryParams = {
      vector: searchVector,
      topK: 50,
      includeMetadata: true,
      filter: initialFilter,
  };
  console.log('Broad Query Params:', JSON.stringify(broadQueryParams, null, 2));
  queries.push(clientPineconeIndex
    .namespace(process.env.PINECONE_NAMESPACE)
    .query(broadQueryParams)
  );

  // Execute all queries in parallel
  const [listingResponse, developmentResponse, broadResponse] = await Promise.all(queries);

  let matches = listingResponse.matches || [];
  const developmentMatches = developmentResponse.matches || [];
  const broadMatches = broadResponse.matches || [];

  console.log(`Found ${matches.length} matches in targeted listing search.`);
  console.log(`Found ${developmentMatches.length} matches in targeted development search.`);
  console.log(`Found ${broadMatches.length} matches in broad search.`);
  
  // Add detailed debugging for broad search
  console.log(`üîç DEBUGGING - Broad Search Details:`);
  console.log(`  Base filter: ${JSON.stringify(baseFilter, null, 2)}`);
  console.log(`  Initial filter (base + query): ${JSON.stringify(initialFilter, null, 2)}`);
  console.log(`  Vector dimensions: ${searchVector.length}`);
  console.log(`  TopK requested: 50`);
  if (broadMatches.length > 0) {
    console.log(`  Best match score: ${broadMatches[0].score}`);
    console.log(`  Worst match score: ${broadMatches[broadMatches.length - 1].score}`);
  }

  const priceMatch = matches.find(match => match.metadata.price_eur !== undefined);
  let currentListingPrice = null;
  if (priceMatch) {
    currentListingPrice = priceMatch.metadata.price_eur;
    console.log(`Current listing (${contextListingId}) price from targeted search: ${currentListingPrice}`);
  }

  const combinedMatches = [...matches, ...developmentMatches];
  const existingIds = new Set(combinedMatches.map(m => m.id));

  broadMatches.forEach(bm => {
    if (!existingIds.has(bm.id)) {
      combinedMatches.push(bm);
    }
  });

  matches = combinedMatches;

  if (matches.length > 0) {
    const queryListingId = extractListingIdFromQuery(originalQuery);
    const reRankQueryFilters = extractQueryFilters(originalQuery, currentListingPrice);

    matches = matches.map(match => {
      let score = match.score;
      if (contextListingId && match.metadata.listing_id === contextListingId) {
        score += 1.0;
      }
      if (queryListingId && match.metadata.listing_id === queryListingId) {
        score += 1.5;
      }
      if (contextDevelopmentId && match.metadata.development_id === contextDevelopmentId) {
        score += 0.8;
      }

      if (Object.keys(reRankQueryFilters).length > 0) {
        let filterMatchCount = 0;
        for (const key in reRankQueryFilters) {
          if (key === 'total_area_sqm' || key === 'price_eur' || key === 'num_bedrooms') {
            if (reRankQueryFilters[key].$lt && match.metadata[key] < reRankQueryFilters[key].$lt) {
              filterMatchCount++;
            } else if (reRankQueryFilters[key].$gt && match.metadata[key] > reRankQueryFilters[key].$gt) {
              filterMatchCount++;
            } else if (match.metadata[key] === reRankQueryFilters[key]) {
              filterMatchCount++;
            }
          } else if (match.metadata[key] === reRankQueryFilters[key]) {
            filterMatchCount++;
          }
        }
        score += (filterMatchCount * 0.2);
      }
      return { ...match, score };
    });

    matches.sort((a, b) => b.score - a.score);
    matches = matches.slice(0, 20);
  }

  return { matches };
}

function isAggregativePriceQuery(query) {
  const lowerCaseQuery = query.toLowerCase();
  return (
    lowerCaseQuery.includes('mais barato') ||
    lowerCaseQuery.includes('pre√ßo mais baixo') ||
    lowerCaseQuery.includes('pre√ßo m√≠nimo') ||
    lowerCaseQuery.includes('mais caro') ||
    lowerCaseQuery.includes('pre√ßo mais alto') ||
    lowerCaseQuery.includes('pre√ßo m√°ximo')
  );
}

async function generateResponse(query, clientConfig, queryEmbeddingVector, externalContext = null, userContext = null, chatHistory = null, onboardingAnswers = null) {
  let aggregativeContext = '';

  if (isAggregativePriceQuery(query)) {
    try {
      if (query.toLowerCase().includes('mais barato') || query.toLowerCase().includes('pre√ßo m√≠nimo')) {
        const minPrice = await listingService.getMinPrice(clientConfig.clientId);
        aggregativeContext = minPrice !== null ? `A propriedade com o pre√ßo mais baixo dispon√≠vel √© de ${minPrice}‚Ç¨.` : `N√£o foi poss√≠vel encontrar o pre√ßo m√≠nimo nos documentos fornecidos.`;
      } else if (query.toLowerCase().includes('mais caro') || query.toLowerCase().includes('pre√ßo m√°ximo')) {
        const maxPrice = await listingService.getMaxPrice(clientConfig.clientId);
        aggregativeContext = maxPrice !== null ? `A propriedade com o pre√ßo mais alto dispon√≠vel √© de ${maxPrice}‚Ç¨.` : `N√£o foi poss√≠vel encontrar o pre√ßo m√°ximo nos documentos fornecidos.`;
      }
      console.log(`Aggregative Price Context: ${aggregativeContext}`);
    } catch (error) {
      console.error('Error fetching aggregative price:', error);
      aggregativeContext = `Ocorreu um erro ao tentar obter informa√ß√µes de pre√ßo.`;
    }
  }

  const queryFilters = extractQueryFilters(query);
  const onboardingFilters = convertOnboardingToFilters(onboardingAnswers);
  const mergedFilters = mergeFilters(queryFilters, onboardingFilters);
  
  // Add debugging for filters
  console.log(`[${clientConfig.clientName}] üîç DEBUGGING - Filters Applied:`);
  console.log(`  Query filters: ${JSON.stringify(queryFilters, null, 2)}`);
  console.log(`  Onboarding filters: ${JSON.stringify(onboardingFilters, null, 2)}`);
  console.log(`  Merged filters: ${JSON.stringify(mergedFilters, null, 2)}`);
  console.log(`  Original query: "${query}"`);
  console.log(`  Onboarding answers: ${JSON.stringify(onboardingAnswers, null, 2)}`);

  let queryResponse;
  try {
    queryResponse = await performHybridSearch(queryEmbeddingVector, clientConfig, externalContext, query, userContext, mergedFilters);
  } catch (error) {
    console.error(`[${clientConfig.clientName}] Error in performHybridSearch:`, error);
    // Return empty matches if search fails due to invalid embedding
    queryResponse = { matches: [] };
  }
  
  // Add debugging for matches found
  console.log(`[${clientConfig.clientName}] üîç DEBUGGING - Search Results:`);
  console.log(`  Total matches found: ${queryResponse.matches.length}`);
  if (queryResponse.matches.length > 0) {
    console.log(`  First match score: ${queryResponse.matches[0].score}`);
    console.log(`  Match metadata keys: ${Object.keys(queryResponse.matches[0].metadata || {})}`);
    queryResponse.matches.slice(0, 3).forEach((match, index) => {
      console.log(`    Match ${index + 1}: ${match.metadata.listing_id || match.metadata.development_id || 'Unknown ID'} (score: ${match.score})`);
    });
  } else {
    console.log(`  ‚ö†Ô∏è No matches found in Pinecone for query: "${query}"`);
    console.log(`  Applied filters: ${JSON.stringify(mergedFilters, null, 2)}`);
  }
  
  // Check if we have no matches and handle accordingly
  if (queryResponse.matches.length === 0) {
    console.log(`[${clientConfig.clientName}] ‚ö†Ô∏è No matches found in Pinecone. The chatbot may generate generic responses or hallucinate listings.`);
  }
  
  let context = queryResponse.matches.map(m => m.metadata.text).join('\n\n---\n\n');
  let remainingTokens = CONTEXT_TOKEN_BUDGET;
  
  // Handle empty context case to prevent hallucination
  if (queryResponse.matches.length === 0) {
    context = "IMPORTANTE: N√£o foram encontradas propriedades na base de dados que correspondam aos crit√©rios especificados. N√ÉO INVENTE ou CRIE informa√ß√µes sobre apartamentos que n√£o existem nos documentos. Informe o utilizador que n√£o h√° propriedades dispon√≠veis que correspondam aos crit√©rios. Apenas mencione propriedades espec√≠ficas da Up Investments (client_id: e6f484a3-c3cb-4e01-b8ce-a276f4b7355c) e n√£o de outros clientes.";
    console.log(`[${clientConfig.clientName}] üìù Using empty context warning to prevent hallucination`);
  }
  
  // Add client filter reminder to prevent incorrect listings
  context += "\n\nIMPORTANTE: Apenas mencione e recomende propriedades que pertencem ao cliente atual (" + clientConfig.clientName + "). N√ÉO RECOMENDE propriedades ou listagens que n√£o pertencem a este cliente. Se n√£o houver propriedades dispon√≠veis que correspondam aos crit√©rios, informe o utilizador de forma clara.";
  
  const contextTokens = encode(context).length;
  remainingTokens -= contextTokens;
  
  // Truncate chat history
  let truncatedChatHistory = '';
  const chatMessagesArray = [];
  if (chatHistory && chatHistory !== "Nenhum hist√≥rico anterior dispon√≠vel") {
    // Ensure chatHistory is a string
    const chatHistoryString = typeof chatHistory === 'string' ? chatHistory : JSON.stringify(chatHistory);
    const historyLines = chatHistoryString.split('\n').reverse(); // Process from newest to oldest
    const tempHistory = [];
    for (const line of historyLines) {
      const lineTokens = encode(line).length;
      if (remainingTokens - lineTokens > 0) {
        tempHistory.unshift(line); // Add to the beginning to maintain order
        remainingTokens -= lineTokens;
      } else {
        break;
      }
    }
    truncatedChatHistory = tempHistory.join('\n');
    
    // Create the messages array for the API call from the truncated history
    for (const line of tempHistory) {
      if (line.startsWith('Utilizador: ')) {
        chatMessagesArray.push({ role: 'user', content: line.replace('Utilizador: ', '') });
      } else if (line.startsWith('Assistente: ')) {
        chatMessagesArray.push({ role: 'assistant', content: line.replace('Assistente: ', '') });
      }
    }
  } else {
      truncatedChatHistory = "Nenhum hist√≥rico anterior dispon√≠vel";
  }

  const systemPromptTemplate = clientConfig.prompts.systemInstruction;
  if (!systemPromptTemplate) {
      throw new Error("System prompt is not defined in the client configuration.");
  }
  
  const templateVariables = {
    onboardingAnswers: onboardingAnswers || "N√£o dispon√≠vel",
    chatHistory: truncatedChatHistory,
    context: context + (aggregativeContext ? `\n\nInforma√ß√£o Adicional:\n${aggregativeContext}` : ''),
    question: query
  };
  let systemPrompt = systemPromptTemplate;
  Object.keys(templateVariables).forEach(key => {
    const placeholder = `{${key}}`;
    // We only replace placeholders in the system prompt template, not the final prompt itself
    systemPrompt = systemPrompt.replace(new RegExp(placeholder, 'g'), templateVariables[key]);
  });
  
  console.log(`[${clientConfig.clientName || clientConfig.clientId}] Using enhanced system prompt. Final token estimate: ${MAX_TOTAL_TOKENS - remainingTokens}`);

  const messages = [
    { role: 'system', content: systemPrompt },
    ...chatMessagesArray,
    { role: 'user', content: query }
  ];

  let retries = 3;
  while (retries > 0) {
    try {
      const completion = await openai.chat.completions.create({
        model: generativeModel,
        messages: messages,
        max_tokens: MAX_RESPONSE_TOKENS,
      });
      return completion.choices[0].message.content;
    } catch (error) {
      if (error.status === 503 && retries > 1) {
        console.log(`Model is overloaded. Retrying in 2 seconds... (${retries - 1} retries left)`);
        await delay(2000);
        retries--;
      } else {
        console.error('Error generating response:', error);
        // Re-throw the error to be handled by the global error handler in index.js
        throw error;
      }
    }
  }

  // If all retries fail, throw an error
  throw new Error('Failed to generate response after multiple retries.');
}

async function generateSuggestedQuestions(clientConfig, externalContext = null, chatHistory = [], userContext = null) {
  let searchQuery = "general information";
  if (externalContext && externalContext.type === 'listing' && externalContext.value) {
    searchQuery = `information about ${externalContext.value}`;
  } else if (chatHistory.length > 0) {
    searchQuery = chatHistory.map(m => m.text).join(' ');
  }

  let queryEmbedding;
  try {
    queryEmbedding = await openai.embeddings.create({
      model: embeddingModel,
      input: searchQuery,
    });
  } catch (error) {
    console.error(`[${clientConfig.clientName}] Error generating embedding for suggested questions:`, error);
    return [];
  }

  // Validate embedding before using it
  if (!queryEmbedding || !queryEmbedding.data || !queryEmbedding.data[0] || !queryEmbedding.data[0].embedding) {
    console.error(`[${clientConfig.clientName}] Invalid embedding response for suggested questions:`, queryEmbedding);
    return [];
  }

  let queryResponse;
  try {
    queryResponse = await performHybridSearch(queryEmbedding.data[0].embedding, clientConfig, externalContext, searchQuery, userContext);
  } catch (error) {
    console.error(`[${clientConfig.clientName}] Error in performHybridSearch for suggested questions:`, error);
    return [];
  }

  if (!queryResponse || queryResponse.matches.length === 0) {
    return [];
  }

  const context = queryResponse.matches
    .map(match => match.metadata.text)
    .join('\n\n---\n\n');

  const prompt = `
    Based on the following context, generate exactly three distinct, relevant, and concise questions a user might ask.
    Format the output as a JSON array of strings. For example: ["Question 1", "Question 2", "Question 3"].
    If you cannot generate three relevant questions from the context, return an empty array [].

    Context:
    ${context}
  `;

  try {
    const completion = await openai.chat.completions.create({
        model: generativeModel,
        messages: [{ role: 'system', content: prompt }],
        response_format: { type: "json_object" },
      });
    const responseText = completion.choices[0].message.content;
    // Basic validation to ensure the response is a parsable JSON array.
    const parsed = JSON.parse(responseText);
    return Array.isArray(parsed) ? parsed : (parsed.questions && Array.isArray(parsed.questions) ? parsed.questions : []);
  } catch (error) {
    console.error("Failed to generate or parse suggested questions:", error);
    return [];
  }
}

export { generateResponse, generateSuggestedQuestions, embeddingModel };
export { generateResponse, generateSuggestedQuestions, embeddingModel };